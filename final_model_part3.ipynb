{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Yuchen(draft)_Modified_ipynb‚Äù.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "LAgAdnnC30Os",
        "Llp9Fw9V931Y",
        "DV3TIMhX2Z-L",
        "Fa6W0Bt1jm3n"
      ],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-q4qlxR2z7P"
      },
      "source": [
        "#Cassava Leaf Disease Classification Project#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAgAdnnC30Os"
      },
      "source": [
        "##Part 1: Import Packages and the Dataset##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Llp9Fw9V931Y"
      },
      "source": [
        "####Import Packages###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7B2a00nj21CF"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import io\n",
        "from keras.preprocessing.image import img_to_array, load_img, ImageDataGenerator\n",
        "from google.colab import drive\n",
        "import json\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9f-xgCSVJg2"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import matplotlib.image as mpimg\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from matplotlib import cm\n",
        "from matplotlib import colors"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4X49nAr2LNfi"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import re\n",
        "from functools import partial"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JErz_aOXGWaM"
      },
      "source": [
        "import keras\n",
        "from keras.layers import Dense, Dropout, Input, MaxPooling2D, ZeroPadding2D, Conv2D, Flatten, BatchNormalization\n",
        "from keras.models import Sequential, Model\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.preprocessing.image import img_to_array, load_img, ImageDataGenerator\n",
        "from keras.utils import to_categorical\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "from tensorflow.keras.layers import MaxPool2D, AveragePooling2D, GlobalAveragePooling2D\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "\n",
        "from zipfile import ZipFile\n",
        "import time\n",
        "from datetime import timedelta\n",
        "from io import BytesIO\n",
        "\n",
        "# Image manipulation.\n",
        "import PIL.Image\n",
        "\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "import random"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Y8u6QNl9mI0"
      },
      "source": [
        "###Mount the Drive###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4It5ZsZBu1D",
        "outputId": "ba6a8779-014c-4eac-e1ee-ec47685ab7e4"
      },
      "source": [
        "import zipfile\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olWInpEOTTlL",
        "outputId": "24dae461-e268-48bd-d271-595ae9dec074"
      },
      "source": [
        "f = open('/content/gdrive/Shareddrives/2040 (unofficial)/my_data/data/label_num_to_disease_map.json')\n",
        "label_name = json.load(f)\n",
        "label_name"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0': 'Cassava Bacterial Blight (CBB)',\n",
              " '1': 'Cassava Brown Streak Disease (CBSD)',\n",
              " '2': 'Cassava Green Mottle (CGM)',\n",
              " '3': 'Cassava Mosaic Disease (CMD)',\n",
              " '4': 'Healthy'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBXCSokGLzWr"
      },
      "source": [
        "###Load the tfrecords###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qzIeXvYQJy2"
      },
      "source": [
        "***Define Some Important Variables***\n",
        "* Batch_Size: 128\n",
        "* Labels: 5 different labels in total \n",
        "* tf.data.AUTOTUNE: promp the tf.data runtime to tune the value dynamically at runtime. \n",
        "* train_path: the path of training dataset directory\n",
        "* test_path: the path of testing dataset directory\n",
        "* Image_Size: 512*512"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tg1ljO3MQS0H"
      },
      "source": [
        "Batch_Size = 128\n",
        "labels = list(label_name.keys())\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "train_path = '/content/gdrive/Shareddrives/2040 (unofficial)/my_data/data/train_tfrecords/ld_train*.tfrec'\n",
        "test_path = '/content/gdrive/Shareddrives/2040 (unofficial)/my_data/data/test_tfrecords/ld_test*.tfrec'\n",
        "Image_Size_Original = [512, 512]\n",
        "image_size = 340"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prC1DDhkFTq9",
        "outputId": "6518bd4d-575e-4602-e883-92c0704beaca"
      },
      "source": [
        "labels"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['0', '1', '2', '3', '4']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYWGgFZhVL-b"
      },
      "source": [
        "***Preprocess the Image***\n",
        "* Decode a JPEG-encoded image to a uint8 tensor.\n",
        "* Divide by 255 to get 0-1 representation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GARnN14JVLJZ"
      },
      "source": [
        "def preprocess_img(img):\n",
        "  img_decode = tf.image.decode_jpeg(img, channels = 3)\n",
        "  img_255 = tf.cast(img_decode, tf.float32)/255.0\n",
        "  img_res = tf.reshape(img_255, [*Image_Size_Original,3])\n",
        "  img_resize = tf.image.resize(img_res, [image_size,image_size])\n",
        "  return img_resize"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJ6VcnmrbqlW"
      },
      "source": [
        "***Read the tfrecord***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HD6iORTMcAqn"
      },
      "source": [
        "##\n",
        "def read_tfrecord(example, labeled):\n",
        "  tfrecord_format = {\"image\":tf.io.FixedLenFeature([], tf.string),\n",
        "                     \"target\":tf.io.FixedLenFeature([], tf.int64),\n",
        "                     } if labeled else {\n",
        "                     \"image\": tf.io.FixedLenFeature([], tf.string),\n",
        "                     \"image_name\": tf.io.FixedLenFeature([], tf.string)\n",
        "                     }\n",
        "  example = tf.io.parse_single_example(example, tfrecord_format)\n",
        "  \n",
        "  img_res = preprocess_img(example['image'])\n",
        "  \n",
        "  if labeled:\n",
        "    label = tf.cast(example['target'], tf.int32)\n",
        "    return img_res, label\n",
        "  else: \n",
        "    id = example['image_name']\n",
        "    return img_res, id"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IJOXSiv0CFS"
      },
      "source": [
        "def read_tfrecord(example, labeled):\n",
        "    tfrecord_format = {\n",
        "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
        "        \"target\": tf.io.FixedLenFeature([], tf.int64)\n",
        "    } if labeled else {\n",
        "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
        "        \"image_name\": tf.io.FixedLenFeature([], tf.string)\n",
        "    }\n",
        "    example = tf.io.parse_single_example(example, tfrecord_format)\n",
        "    image = preprocess_img(example['image'])\n",
        "    if labeled:\n",
        "        label = tf.cast(example['target'], tf.int32)\n",
        "        return image, label\n",
        "    idnum = example['image_name']\n",
        "    return image, idnum"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58OslozvfGG2"
      },
      "source": [
        "***Load the dataset***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnfxEHq90NvO"
      },
      "source": [
        "##\n",
        "def load_dataset(filenames, labeled=True, ordered=False):\n",
        "    ignore_order = tf.data.Options()\n",
        "    if not ordered:\n",
        "        ignore_order.experimental_deterministic = False # disable order, increase speed\n",
        "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE) # automatically interleaves reads from multiple files\n",
        "    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n",
        "    dataset = dataset.map(partial(read_tfrecord, labeled=labeled), num_parallel_calls=AUTOTUNE)\n",
        "    return dataset"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GOYayzMLjf7"
      },
      "source": [
        "###Splitting Strategy###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUQxbYmvKe1Q"
      },
      "source": [
        "df_training, df_validation = train_test_split(tf.io.gfile.glob(train_path),\n",
        "                                              test_size=0.2, random_state=42)\n",
        "df_testing = tf.io.gfile.glob(test_path)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15flHecLL7bv",
        "outputId": "cc96cc23-4d92-4018-f749-e2b1fbae9d60"
      },
      "source": [
        "len(df_training), len(df_validation), len(df_testing)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12, 4, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xam-MpAoFp9i",
        "outputId": "d55fd79b-542f-480a-ca37-85bda1df8793"
      },
      "source": [
        "df_training, df_validation, df_testing"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['/content/gdrive/Shareddrives/2040 (unofficial)/my_data/data/train_tfrecords/ld_train13-1338.tfrec',\n",
              "  '/content/gdrive/Shareddrives/2040 (unofficial)/my_data/data/train_tfrecords/ld_train11-1338.tfrec',\n",
              "  '/content/gdrive/Shareddrives/2040 (unofficial)/my_data/data/train_tfrecords/ld_train08-1338.tfrec',\n",
              "  '/content/gdrive/Shareddrives/2040 (unofficial)/my_data/data/train_tfrecords/ld_train09-1338.tfrec',\n",
              "  '/content/gdrive/Shareddrives/2040 (unofficial)/my_data/data/train_tfrecords/ld_train02-1338.tfrec',\n",
              "  '/content/gdrive/Shareddrives/2040 (unofficial)/my_data/data/train_tfrecords/ld_train15-1327.tfrec',\n",
              "  '/content/gdrive/Shareddrives/2040 (unofficial)/my_data/data/train_tfrecords/ld_train04-1338.tfrec',\n",
              "  '/content/gdrive/Shareddrives/2040 (unofficial)/my_data/data/train_tfrecords/ld_train07-1338.tfrec',\n",
              "  '/content/gdrive/Shareddrives/2040 (unofficial)/my_data/data/train_tfrecords/ld_train10-1338.tfrec',\n",
              "  '/content/gdrive/Shareddrives/2040 (unofficial)/my_data/data/train_tfrecords/ld_train12-1338.tfrec',\n",
              "  '/content/gdrive/Shareddrives/2040 (unofficial)/my_data/data/train_tfrecords/ld_train03-1338.tfrec',\n",
              "  '/content/gdrive/Shareddrives/2040 (unofficial)/my_data/data/train_tfrecords/ld_train06-1338.tfrec'],\n",
              " ['/content/gdrive/Shareddrives/2040 (unofficial)/my_data/data/train_tfrecords/ld_train00-1338.tfrec',\n",
              "  '/content/gdrive/Shareddrives/2040 (unofficial)/my_data/data/train_tfrecords/ld_train01-1338.tfrec',\n",
              "  '/content/gdrive/Shareddrives/2040 (unofficial)/my_data/data/train_tfrecords/ld_train05-1338.tfrec',\n",
              "  '/content/gdrive/Shareddrives/2040 (unofficial)/my_data/data/train_tfrecords/ld_train14-1338.tfrec'],\n",
              " ['/content/gdrive/Shareddrives/2040 (unofficial)/my_data/data/test_tfrecords/ld_test00-1.tfrec'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrTKH_B4sJUQ"
      },
      "source": [
        "###Image Augmentation###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQ2S9orkNFAh"
      },
      "source": [
        "def train_augmentation(image, label):\n",
        "#image_augmentation¬†\n",
        "  image = tf.image.random_flip_left_right(image)\n",
        "  image = tf.image.random_flip_up_down(image)\n",
        " # image = tf.image.random_hue(image, 0.2)\n",
        "  image = tf.image.random_crop(image, [image_size, image_size, 3])\n",
        " # image = tf.image.random_brightness(image, max_delta=0.5)\n",
        " # image = tf.image.random_saturation(image, lower = 5, upper = 10)\n",
        " # image = tf.image.random_contrast(image, 0.2, 0.5)\n",
        " # image = tf.image.random_jpeg_quality(image, 75, 95)\n",
        "  return image, label"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MEqGap_cxdc"
      },
      "source": [
        "###Load the dataset###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ib7NUnrXqGrt"
      },
      "source": [
        "* repeat: repeats this dataset so each original value is seen infinitely. \n",
        "* shuffle: randomly shuffles the elements of this dataet. \n",
        "* prefetch: allows later elements to be prepared while the current element is being processed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ki0eW2N8Mxg3"
      },
      "source": [
        "def get_training_dataset():\n",
        "    df_train = load_dataset(df_training, labeled=True)  \n",
        "    df_train = df_train.map(train_augmentation, num_parallel_calls=AUTOTUNE)  \n",
        "    df_train = df_train.repeat()\n",
        "    df_train = df_train.shuffle(2048)\n",
        "    df_train = df_train.batch(Batch_Size)\n",
        "    df_train = df_train.prefetch(AUTOTUNE) # allows later elements to be prepared while the current element is being processed.\n",
        "    return df_train"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8FBsKaPNJGV"
      },
      "source": [
        "def get_validation_dataset(ordered=False):\n",
        "    df_valid = load_dataset(df_validation, labeled=True, ordered=ordered) \n",
        "    df_valid = df_valid.batch(Batch_Size)\n",
        "    df_valid = df_valid.cache()\n",
        "    df_valid = df_valid.prefetch(AUTOTUNE)\n",
        "    return df_valid"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPcBqwfTNLBA"
      },
      "source": [
        "def get_test_dataset(ordered=False):\n",
        "    df_test = load_dataset(df_testing, labeled=False, ordered=ordered)\n",
        "    df_test = df_test.batch(Batch_Size)\n",
        "    df_test = df_test.prefetch(AUTOTUNE)\n",
        "    return df_test"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlfnY60jNNcd"
      },
      "source": [
        "def counting_items(filenames):\n",
        "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
        "    return np.sum(n)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5Jt1XVBNOlK",
        "outputId": "e56b0359-4a1c-469a-baed-efb8e0dd4148"
      },
      "source": [
        "num_training = counting_items(df_training)\n",
        "num_valid = counting_items(df_validation)\n",
        "num_test = counting_items(df_testing)\n",
        "\n",
        "print('This Dataset: {} training images, {} validation images, {} (unlabeled) test images'.format(\n",
        "    num_training, num_valid, num_test))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This Dataset: 16045 training images, 5352 validation images, 1 (unlabeled) test images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7QhAHL_N1TL"
      },
      "source": [
        "df_train = get_training_dataset()\n",
        "df_valid = get_validation_dataset()\n",
        "df_test = get_test_dataset()"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2H92IVApOSYP",
        "outputId": "a3779d7e-5108-4b90-bad3-717c1e01a710"
      },
      "source": [
        "df_train, df_valid, df_test"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<PrefetchDataset shapes: ((None, 340, 340, 3), (None,)), types: (tf.float32, tf.int32)>,\n",
              " <PrefetchDataset shapes: ((None, 340, 340, 3), (None,)), types: (tf.float32, tf.int32)>,\n",
              " <PrefetchDataset shapes: ((None, 340, 340, 3), (None,)), types: (tf.float32, tf.string)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxgJx_tzvycb",
        "outputId": "0ae29bfa-e746-4aab-dec5-e76aa7e96fe6"
      },
      "source": [
        "print(\"Training dataset:\")\n",
        "for image, label in df_train.take(3):\n",
        "    print(image.numpy().shape, label.numpy().shape)\n",
        "    print(\"Training dataset labels:\", label.numpy())\n",
        "print(\"Validation dataset:\")\n",
        "for image, label in df_valid.take(3):\n",
        "    print(image.numpy().shape, label.numpy().shape)\n",
        "    print(\"Validation dataset labels:\", label.numpy())\n",
        "print(\"Test dataset:\")\n",
        "for image, idnum in df_test.take(3):\n",
        "    print(image.numpy().shape, idnum.numpy().shape)\n",
        "    print(\"Test data IDs:\", idnum.numpy().astype('U')) \n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training dataset:\n",
            "(128, 340, 340, 3) (128,)\n",
            "Training dataset labels: [3 3 3 0 3 0 3 4 3 3 3 3 2 3 0 3 1 3 2 3 2 2 3 3 3 0 0 1 3 3 3 3 3 4 3 4 3\n",
            " 3 0 4 3 3 3 3 3 3 3 4 4 3 3 3 3 3 1 4 3 4 2 2 3 3 3 3 2 3 3 3 3 1 2 4 3 3\n",
            " 3 4 1 3 2 3 3 3 3 4 3 4 3 3 3 3 3 3 3 3 3 3 2 3 4 3 3 3 1 4 3 1 3 3 3 4 3\n",
            " 1 3 3 3 3 3 3 3 1 2 3 3 3 3 3 4 3]\n",
            "(128, 340, 340, 3) (128,)\n",
            "Training dataset labels: [3 3 1 0 2 3 3 3 1 3 2 1 3 3 3 4 3 3 0 3 3 0 4 4 3 4 1 3 3 3 3 3 0 3 1 2 3\n",
            " 3 4 4 3 3 3 1 3 4 3 3 0 3 3 3 3 3 4 3 3 4 3 3 3 3 2 4 3 1 3 4 3 0 3 4 3 3\n",
            " 3 3 3 0 1 3 2 3 3 3 4 3 2 3 1 4 3 3 3 3 3 4 3 4 4 3 3 3 3 3 1 3 1 2 3 0 3\n",
            " 3 3 3 3 3 1 3 4 3 3 3 4 3 3 1 3 3]\n",
            "(128, 340, 340, 3) (128,)\n",
            "Training dataset labels: [3 3 2 3 3 1 2 3 3 0 0 3 4 3 3 2 2 3 3 3 3 3 2 3 2 3 3 3 1 4 2 3 3 1 3 3 3\n",
            " 3 3 3 4 3 3 4 1 3 3 3 1 3 4 3 1 3 1 3 3 3 1 2 3 3 4 3 3 2 2 3 3 3 2 2 2 3\n",
            " 3 4 1 2 4 3 3 3 3 3 2 1 0 0 3 2 3 2 2 4 2 3 3 3 3 3 3 3 3 4 3 3 3 3 3 2 3\n",
            " 3 3 3 0 0 3 3 3 2 3 3 3 3 3 2 1 3]\n",
            "Validation dataset:\n",
            "(128, 340, 340, 3) (128,)\n",
            "Validation dataset labels: [0 3 1 1 3 3 2 0 4 3 3 3 1 3 3 3 2 3 3 4 1 0 1 3 3 3 3 3 3 1 2 3 4 2 4 2 2\n",
            " 3 0 3 2 2 3 2 3 4 3 3 1 3 4 3 3 3 3 3 3 3 3 3 3 3 3 3 1 1 3 3 2 1 2 4 3 1\n",
            " 3 2 3 3 4 3 4 3 3 1 3 3 3 2 0 3 3 3 3 3 1 3 3 4 3 3 3 3 1 3 3 3 3 3 1 3 4\n",
            " 3 3 1 3 3 3 3 3 3 2 1 3 3 3 3 3 3]\n",
            "(128, 340, 340, 3) (128,)\n",
            "Validation dataset labels: [2 3 4 3 3 2 4 3 3 1 3 3 3 4 3 3 3 3 3 3 2 3 3 4 3 2 3 3 4 4 3 4 1 3 3 0 3\n",
            " 1 3 3 3 1 4 3 3 1 3 4 0 3 4 3 3 3 2 4 1 2 3 3 3 3 3 1 0 3 3 3 3 3 1 3 3 2\n",
            " 1 1 1 3 3 3 3 3 1 1 1 3 2 3 3 1 2 3 4 3 2 2 2 0 4 3 3 3 2 4 1 3 2 0 3 2 3\n",
            " 3 4 4 0 3 3 3 3 3 0 3 3 3 3 0 3 3]\n",
            "(128, 340, 340, 3) (128,)\n",
            "Validation dataset labels: [3 3 2 1 4 2 3 0 3 3 2 3 0 3 3 3 1 3 3 3 2 4 3 3 3 4 3 3 3 3 3 4 3 0 3 3 1\n",
            " 2 3 3 2 1 4 0 3 3 3 3 3 3 3 2 3 3 3 2 2 3 3 3 3 3 3 2 3 0 2 3 3 1 3 3 4 3\n",
            " 4 4 3 0 1 3 3 3 2 3 4 3 3 3 4 3 3 1 2 3 3 3 3 3 3 4 3 3 2 1 3 3 3 4 3 1 3\n",
            " 4 2 3 1 0 3 3 0 3 1 2 4 3 4 3 3 3]\n",
            "Test dataset:\n",
            "(1, 340, 340, 3) (1,)\n",
            "Test data IDs: ['2216849948.jpg']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fa6W0Bt1jm3n"
      },
      "source": [
        "##Part2: Model Selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g41tF6vvjzOy"
      },
      "source": [
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import AveragePooling2D, GlobalMaxPooling2D\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.regularizers import l1, l2\n",
        "from tensorflow.keras import callbacks\n",
        "from keras.applications import *\n",
        "from keras.callbacks import LearningRateScheduler,ReduceLROnPlateau, ModelCheckpoint\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAbnuZSoLmba"
      },
      "source": [
        "### Resnet101V2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0tXQVgsLeWX"
      },
      "source": [
        "steps_per_epoch = num_training// Batch_Size\n",
        "valid_steps = num_valid // Batch_Size"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVZUrXpLLeaf"
      },
      "source": [
        "early_stopping1 = callbacks.EarlyStopping(patience= 10, restore_best_weights=True)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ztD1B8Y3LMp"
      },
      "source": [
        "#### Define model with compile"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMS75cz6LUF-"
      },
      "source": [
        "def make_model(opt, reg_rate):\n",
        "  base_resnet = tf.keras.applications.ResNet101V2(include_top = False, \n",
        "                        input_shape=(image_size, image_size, 3),\n",
        "                        weights=\"imagenet\", \n",
        "                        classifier_activation=\"softmax\")\n",
        "  for layer in base_resnet.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "  head = base_resnet.output\n",
        "\n",
        "  head = GlobalMaxPooling2D()(head)\n",
        "  head = Flatten()(head)\n",
        "  head = Dense(512, kernel_initializer = 'he_normal', \n",
        "              kernel_regularizer=l1(reg_rate))(head)\n",
        "  head = BatchNormalization()(head)\n",
        "  head = Activation('relu')(head)\n",
        "  head = Dropout(rate=0.5)(head)\n",
        "\n",
        "  # head = Dense(64)(head)\n",
        "  # head = BatchNormalization()(head)\n",
        "  # #head = Activation('relu')(head)\n",
        "  # head = LeakyReLU()(head)\n",
        "  head = Dense(5, activation ='softmax')(head)\n",
        "\n",
        "  model = Model(inputs = base_resnet.input, outputs =head)\n",
        "\n",
        "  model.compile(\n",
        "    optimizer = opt,\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "  return model"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRhi4KqBo-9I",
        "outputId": "ee0e8385-bb2d-420e-b004-895e1f4821e2"
      },
      "source": [
        "opt = keras.optimizers.Adam(0.0001) \n",
        "model1 = make_model(opt, 0.01)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet101v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "171319296/171317808 [==============================] - 3s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 917
        },
        "id": "9WkSpkLSpYPn",
        "outputId": "b16de4da-aca9-470a-fbbb-50ba100965b8"
      },
      "source": [
        "history1 = model1.fit(df_train, validation_data= df_valid, steps_per_epoch=steps_per_epoch, \n",
        "                shuffle= True, epochs=100, callbacks=[early_stopping1])"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "125/125 [==============================] - 155s 1s/step - loss: 241.4902 - accuracy: 0.4794 - val_loss: 163.2515 - val_accuracy: 0.6287\n",
            "Epoch 2/100\n",
            "125/125 [==============================] - 119s 952ms/step - loss: 142.7725 - accuracy: 0.5986 - val_loss: 89.3295 - val_accuracy: 0.6590\n",
            "Epoch 3/100\n",
            "125/125 [==============================] - 119s 953ms/step - loss: 76.3388 - accuracy: 0.6251 - val_loss: 43.5324 - val_accuracy: 0.6839\n",
            "Epoch 4/100\n",
            "125/125 [==============================] - 119s 952ms/step - loss: 36.2133 - accuracy: 0.6623 - val_loss: 18.5870 - val_accuracy: 0.6958\n",
            "Epoch 5/100\n",
            "125/125 [==============================] - 119s 954ms/step - loss: 15.1582 - accuracy: 0.6666 - val_loss: 7.4078 - val_accuracy: 0.7081\n",
            "Epoch 6/100\n",
            "125/125 [==============================] - 119s 953ms/step - loss: 6.2572 - accuracy: 0.6804 - val_loss: 3.9420 - val_accuracy: 0.6889\n",
            "Epoch 7/100\n",
            "125/125 [==============================] - 119s 952ms/step - loss: 3.7376 - accuracy: 0.6808 - val_loss: 3.2565 - val_accuracy: 0.6805\n",
            "Epoch 8/100\n",
            "125/125 [==============================] - 119s 952ms/step - loss: 3.1355 - accuracy: 0.6842 - val_loss: 2.9102 - val_accuracy: 0.6945\n",
            "Epoch 9/100\n",
            "125/125 [==============================] - 119s 952ms/step - loss: 2.8922 - accuracy: 0.6996 - val_loss: 2.8608 - val_accuracy: 0.6825\n",
            "Epoch 10/100\n",
            "125/125 [==============================] - 119s 952ms/step - loss: 2.8296 - accuracy: 0.6880 - val_loss: 2.7742 - val_accuracy: 0.6883\n",
            "Epoch 11/100\n",
            "125/125 [==============================] - 119s 952ms/step - loss: 2.7435 - accuracy: 0.6915 - val_loss: 2.8579 - val_accuracy: 0.6536\n",
            "Epoch 12/100\n",
            "125/125 [==============================] - 119s 952ms/step - loss: 2.7264 - accuracy: 0.6890 - val_loss: 2.8912 - val_accuracy: 0.6654\n",
            "Epoch 13/100\n",
            "125/125 [==============================] - 119s 953ms/step - loss: 2.6525 - accuracy: 0.6963 - val_loss: 2.8356 - val_accuracy: 0.6775\n",
            "Epoch 14/100\n",
            "125/125 [==============================] - 119s 952ms/step - loss: 2.6228 - accuracy: 0.6953 - val_loss: 2.6201 - val_accuracy: 0.7067\n",
            "Epoch 15/100\n",
            "125/125 [==============================] - 119s 952ms/step - loss: 2.6107 - accuracy: 0.6981 - val_loss: 2.6315 - val_accuracy: 0.6857\n",
            "Epoch 16/100\n",
            "113/125 [==========================>...] - ETA: 8s - loss: 2.5889 - accuracy: 0.6934"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-b9461ef8e612>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m history1 = model1.fit(df_train, validation_data= df_valid, steps_per_epoch=steps_per_epoch, \n\u001b[0;32m----> 2\u001b[0;31m                 shuffle= True, epochs=100, callbacks=[early_stopping1])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1I-5hsy3RPB"
      },
      "source": [
        "#### Adam Optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOEaxcqdpwIt"
      },
      "source": [
        "Frozen  last 5 layers (last block), change batch size to 32"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qa3Q2osgdocE"
      },
      "source": [
        "batch_size = 32\n",
        "steps_per_epoch = num_training// batch_size\n",
        "valid_steps = num_valid // batch_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        },
        "id": "McXKaQqPyNv1",
        "outputId": "24b208e5-9b0b-43a7-c1d7-5f9c0665e7c9"
      },
      "source": [
        "base_resnet = tf.keras.applications.ResNet101V2(include_top = False, \n",
        "                        input_shape=(image_size, image_size, 3),\n",
        "                        weights=\"imagenet\")\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001, cooldown=1)\n",
        "\n",
        "for layer in base_resnet.layers[:-5]:\n",
        "  layer.trainable = False\n",
        "\n",
        "head = base_resnet.output\n",
        "\n",
        "head = GlobalMaxPooling2D()(head)\n",
        "head = Flatten()(head)\n",
        "\n",
        "head = Dense(128, activation='relu', kernel_initializer='he_normal', kernel_regularizer=regularizers.l1_l2(l2=0.001))(head)\n",
        "head = BatchNormalization()(head)\n",
        "\n",
        "head = Dense(64, activation='relu', kernel_initializer='he_normal', kernel_regularizer=regularizers.l1_l2(l2=0.001))(head)\n",
        "head = BatchNormalization()(head)\n",
        "\n",
        "head = Dense(5, activation ='softmax')(head)\n",
        "\n",
        "model2 = Model(inputs = base_resnet.input, outputs =head)\n",
        "\n",
        "model2.compile(\n",
        "  optimizer = opt,\n",
        "  loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "  metrics=['accuracy']\n",
        ")\n",
        "\n",
        "\n",
        "opt = keras.optimizers.Adam(0.0001) \n",
        "\n",
        "history2 = model2.fit(df_train, validation_data= df_valid, steps_per_epoch=steps_per_epoch, \n",
        "                shuffle= True, epochs=100, callbacks=[early_stopping1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "501/501 [==============================] - 238s 428ms/step - loss: 33.8986 - accuracy: 0.4078 - val_loss: 23.3932 - val_accuracy: 0.5133\n",
            "Epoch 2/100\n",
            "501/501 [==============================] - 213s 425ms/step - loss: 20.2405 - accuracy: 0.6290 - val_loss: 13.3378 - val_accuracy: 0.5729\n",
            "Epoch 3/100\n",
            "501/501 [==============================] - 212s 424ms/step - loss: 11.2917 - accuracy: 0.6569 - val_loss: 7.3689 - val_accuracy: 0.5854\n",
            "Epoch 4/100\n",
            "255/501 [==============>...............] - ETA: 1:35 - loss: 6.5958 - accuracy: 0.6675"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-7ce315f840f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m history1 = model.fit(df_train, validation_data= df_valid, steps_per_epoch=steps_per_epoch, \n\u001b[0;32m---> 35\u001b[0;31m                 shuffle= True, epochs=100, callbacks=[early_stopping1, reduce_lr])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jph7I-zJ1z6l",
        "outputId": "fd50d950-6062-47dc-bd7e-5ac3602e2397"
      },
      "source": [
        "## !git clone https://github.com/christianversloot/CLR.git\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'CLR' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_R9nty0FpiIu"
      },
      "source": [
        "#### Cyclic learning rate (CLR) trial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKXQ05gcqvNO"
      },
      "source": [
        "Cyclic learning rate (CLR) with batch size 128 and adam optimizer learning rate as 0.0001. CLR helps training process escape from local minimum or converge faster when starts new training plateau."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLHTwbreqF5w"
      },
      "source": [
        "batch_size = 128\n",
        "steps_per_epoch = num_training// batch_size\n",
        "valid_steps = num_valid // batch_size "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9fuxFs_encP"
      },
      "source": [
        "from CLR.clr_callback import CyclicLR\n",
        "\n",
        "# Set CLR options\n",
        "clr_step_size = int(4 * (num_training/batch_size))\n",
        "base_lr = 1e-4\n",
        "max_lr = 1e-2\n",
        "mode='triangular'\n",
        "no_epochs = 50\n",
        "\n",
        "clr = CyclicLR(base_lr = base_lr, max_lr = max_lr, step_size = clr_step_size, mode = mode)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RayRGMWkyNyU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b810ecf1-f62b-42d5-e338-7bfbfb8afeaa"
      },
      "source": [
        "base_resnet = tf.keras.applications.ResNet101V2(include_top = False, \n",
        "                        input_shape=(image_size, image_size, 3),\n",
        "                        weights=\"imagenet\")\n",
        "for layer in base_resnet.layers[:-10]:\n",
        "  layer.trainable = False\n",
        "\n",
        "head = base_resnet.output\n",
        "\n",
        "head = GlobalMaxPooling2D()(head)\n",
        "head = Flatten()(head)\n",
        "\n",
        "\n",
        "head = Dense(64, activation='relu', kernel_initializer='he_normal', kernel_regularizer=regularizers.l1_l2(l2=0.01))(head)\n",
        "head = BatchNormalization()(head)\n",
        "\n",
        "head = Dense(5, activation ='softmax')(head)\n",
        "\n",
        "model = Model(inputs = base_resnet.input, outputs =head)\n",
        "\n",
        "model.compile(\n",
        "  optimizer = opt,\n",
        "  loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "  metrics=['accuracy']\n",
        ")\n",
        "\n",
        "opt = keras.optimizers.Adam(0.0001) \n",
        "\n",
        "history3 = model3.fit(df_train, validation_data= df_valid, steps_per_epoch=steps_per_epoch, \n",
        "                shuffle= True, epochs=100, callbacks=[early_stopping1, clr])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "125/125 [==============================] - 75s 503ms/step - loss: 36.9438 - accuracy: 0.3186 - val_loss: 34.3223 - val_accuracy: 0.3668\n",
            "Epoch 2/50\n",
            "125/125 [==============================] - 60s 484ms/step - loss: 32.7799 - accuracy: 0.4941 - val_loss: 30.7869 - val_accuracy: 0.3552\n",
            "Epoch 3/50\n",
            "125/125 [==============================] - 60s 478ms/step - loss: 29.0696 - accuracy: 0.5691 - val_loss: 26.9652 - val_accuracy: 0.4524\n",
            "Epoch 4/50\n",
            "125/125 [==============================] - 58s 467ms/step - loss: 25.6573 - accuracy: 0.6011 - val_loss: 23.7616 - val_accuracy: 0.4737\n",
            "Epoch 5/50\n",
            "125/125 [==============================] - 56s 451ms/step - loss: 22.5502 - accuracy: 0.6249 - val_loss: 20.9080 - val_accuracy: 0.4688\n",
            "Epoch 6/50\n",
            "125/125 [==============================] - 56s 445ms/step - loss: 19.7456 - accuracy: 0.6337 - val_loss: 18.0899 - val_accuracy: 0.5575\n",
            "Epoch 7/50\n",
            "125/125 [==============================] - 56s 449ms/step - loss: 17.2152 - accuracy: 0.6473 - val_loss: 15.9071 - val_accuracy: 0.5323\n",
            "Epoch 8/50\n",
            "125/125 [==============================] - 56s 451ms/step - loss: 14.9313 - accuracy: 0.6569 - val_loss: 13.6694 - val_accuracy: 0.5774\n",
            "Epoch 9/50\n",
            "125/125 [==============================] - 56s 451ms/step - loss: 12.9500 - accuracy: 0.6554 - val_loss: 11.8175 - val_accuracy: 0.5906\n",
            "Epoch 10/50\n",
            "125/125 [==============================] - 56s 446ms/step - loss: 11.1889 - accuracy: 0.6619 - val_loss: 10.1426 - val_accuracy: 0.6243\n",
            "Epoch 11/50\n",
            "125/125 [==============================] - 54s 435ms/step - loss: 9.6654 - accuracy: 0.6615 - val_loss: 8.8506 - val_accuracy: 0.5983\n",
            "Epoch 12/50\n",
            "125/125 [==============================] - 55s 438ms/step - loss: 8.3179 - accuracy: 0.6691 - val_loss: 7.6185 - val_accuracy: 0.6013\n",
            "Epoch 13/50\n",
            "125/125 [==============================] - 55s 439ms/step - loss: 7.1728 - accuracy: 0.6693 - val_loss: 6.6574 - val_accuracy: 0.5792\n",
            "Epoch 14/50\n",
            "125/125 [==============================] - 55s 440ms/step - loss: 6.1968 - accuracy: 0.6734 - val_loss: 5.8460 - val_accuracy: 0.5547\n",
            "Epoch 15/50\n",
            "125/125 [==============================] - 54s 435ms/step - loss: 5.3642 - accuracy: 0.6730 - val_loss: 4.9966 - val_accuracy: 0.6048\n",
            "Epoch 16/50\n",
            "125/125 [==============================] - 55s 441ms/step - loss: 4.6578 - accuracy: 0.6770 - val_loss: 4.2472 - val_accuracy: 0.6691\n",
            "Epoch 17/50\n",
            "125/125 [==============================] - 55s 442ms/step - loss: 4.0603 - accuracy: 0.6844 - val_loss: 3.7473 - val_accuracy: 0.6598\n",
            "Epoch 18/50\n",
            "125/125 [==============================] - 55s 443ms/step - loss: 3.5798 - accuracy: 0.6779 - val_loss: 3.4594 - val_accuracy: 0.5944\n",
            "Epoch 19/50\n",
            "125/125 [==============================] - 56s 447ms/step - loss: 3.1695 - accuracy: 0.6773 - val_loss: 3.0082 - val_accuracy: 0.6463\n",
            "Epoch 20/50\n",
            "125/125 [==============================] - 56s 448ms/step - loss: 2.8313 - accuracy: 0.6806 - val_loss: 2.6426 - val_accuracy: 0.6794\n",
            "Epoch 21/50\n",
            "125/125 [==============================] - 56s 448ms/step - loss: 2.5412 - accuracy: 0.6860 - val_loss: 2.4208 - val_accuracy: 0.6639\n",
            "Epoch 22/50\n",
            "125/125 [==============================] - 56s 452ms/step - loss: 2.3458 - accuracy: 0.6784 - val_loss: 2.2492 - val_accuracy: 0.6543\n",
            "Epoch 23/50\n",
            "125/125 [==============================] - 56s 452ms/step - loss: 2.1389 - accuracy: 0.6819 - val_loss: 2.1679 - val_accuracy: 0.6205\n",
            "Epoch 24/50\n",
            "125/125 [==============================] - 56s 447ms/step - loss: 1.9669 - accuracy: 0.6911 - val_loss: 2.0311 - val_accuracy: 0.6121\n",
            "Epoch 25/50\n",
            "125/125 [==============================] - 54s 435ms/step - loss: 1.8545 - accuracy: 0.6848 - val_loss: 1.8349 - val_accuracy: 0.6627\n",
            "Epoch 26/50\n",
            "125/125 [==============================] - 55s 439ms/step - loss: 1.7434 - accuracy: 0.6909 - val_loss: 1.9199 - val_accuracy: 0.5863\n",
            "Epoch 27/50\n",
            "125/125 [==============================] - 55s 438ms/step - loss: 1.6401 - accuracy: 0.6861 - val_loss: 1.7592 - val_accuracy: 0.6349\n",
            "Epoch 28/50\n",
            "125/125 [==============================] - 55s 442ms/step - loss: 1.5557 - accuracy: 0.6882 - val_loss: 1.8660 - val_accuracy: 0.5334\n",
            "Epoch 29/50\n",
            "125/125 [==============================] - 55s 442ms/step - loss: 1.4802 - accuracy: 0.6917 - val_loss: 2.0248 - val_accuracy: 0.4210\n",
            "Epoch 30/50\n",
            "125/125 [==============================] - 55s 439ms/step - loss: 1.4282 - accuracy: 0.6872 - val_loss: 1.4454 - val_accuracy: 0.6588\n",
            "Epoch 31/50\n",
            "125/125 [==============================] - 55s 442ms/step - loss: 1.3629 - accuracy: 0.6933 - val_loss: 1.3621 - val_accuracy: 0.6786\n",
            "Epoch 32/50\n",
            "125/125 [==============================] - 55s 444ms/step - loss: 1.3185 - accuracy: 0.6938 - val_loss: 1.2979 - val_accuracy: 0.6906\n",
            "Epoch 33/50\n",
            "125/125 [==============================] - 56s 445ms/step - loss: 1.2896 - accuracy: 0.6877 - val_loss: 1.4307 - val_accuracy: 0.6076\n",
            "Epoch 34/50\n",
            "125/125 [==============================] - 56s 449ms/step - loss: 1.2429 - accuracy: 0.6969 - val_loss: 1.5571 - val_accuracy: 0.5637\n",
            "Epoch 35/50\n",
            "125/125 [==============================] - 56s 450ms/step - loss: 1.2065 - accuracy: 0.6974 - val_loss: 1.3710 - val_accuracy: 0.6220\n",
            "Epoch 36/50\n",
            "125/125 [==============================] - 56s 451ms/step - loss: 1.1752 - accuracy: 0.6941 - val_loss: 1.3417 - val_accuracy: 0.6431\n",
            "Epoch 37/50\n",
            "125/125 [==============================] - 56s 447ms/step - loss: 1.1440 - accuracy: 0.6973 - val_loss: 1.2766 - val_accuracy: 0.6388\n",
            "Epoch 38/50\n",
            "125/125 [==============================] - 54s 436ms/step - loss: 1.1198 - accuracy: 0.6961 - val_loss: 1.2009 - val_accuracy: 0.6616\n",
            "Epoch 39/50\n",
            "125/125 [==============================] - 55s 437ms/step - loss: 1.1035 - accuracy: 0.6971 - val_loss: 1.2125 - val_accuracy: 0.6323\n",
            "Epoch 40/50\n",
            "125/125 [==============================] - 55s 438ms/step - loss: 1.0967 - accuracy: 0.6925 - val_loss: 1.1002 - val_accuracy: 0.6889\n",
            "Epoch 41/50\n",
            "125/125 [==============================] - 55s 439ms/step - loss: 1.0745 - accuracy: 0.6961 - val_loss: 1.1290 - val_accuracy: 0.6635\n",
            "Epoch 42/50\n",
            "125/125 [==============================] - 55s 439ms/step - loss: 1.0510 - accuracy: 0.6969 - val_loss: 1.2425 - val_accuracy: 0.5968\n",
            "Epoch 43/50\n",
            "125/125 [==============================] - 55s 441ms/step - loss: 1.0187 - accuracy: 0.7050 - val_loss: 1.1926 - val_accuracy: 0.6390\n",
            "Epoch 44/50\n",
            "125/125 [==============================] - 55s 441ms/step - loss: 1.0303 - accuracy: 0.6929 - val_loss: 1.1834 - val_accuracy: 0.6188\n",
            "Epoch 45/50\n",
            "125/125 [==============================] - 55s 442ms/step - loss: 1.0036 - accuracy: 0.6979 - val_loss: 1.2062 - val_accuracy: 0.5912\n",
            "Epoch 46/50\n",
            "125/125 [==============================] - 55s 444ms/step - loss: 0.9932 - accuracy: 0.7002 - val_loss: 0.9948 - val_accuracy: 0.6962\n",
            "Epoch 47/50\n",
            "125/125 [==============================] - 56s 448ms/step - loss: 0.9689 - accuracy: 0.7040 - val_loss: 1.1444 - val_accuracy: 0.6211\n",
            "Epoch 48/50\n",
            "125/125 [==============================] - 56s 449ms/step - loss: 0.9693 - accuracy: 0.7019 - val_loss: 1.0771 - val_accuracy: 0.6594\n",
            "Epoch 49/50\n",
            "125/125 [==============================] - 56s 451ms/step - loss: 0.9589 - accuracy: 0.7003 - val_loss: 0.9531 - val_accuracy: 0.6984\n",
            "Epoch 50/50\n",
            "125/125 [==============================] - 55s 444ms/step - loss: 0.9419 - accuracy: 0.7049 - val_loss: 0.9937 - val_accuracy: 0.6712\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7f_12kpqfcR"
      },
      "source": [
        "#### Reduce learning rate schedule"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpcF9wEQyN1h"
      },
      "source": [
        "batch_size = 32\n",
        "steps_per_epoch = num_training// batch_size\n",
        "valid_steps = num_valid // batch_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPih3kaEqd4e"
      },
      "source": [
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=0.00001, cooldown=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "X6j0TumEEKcs",
        "outputId": "b9a2da7a-9fef-4f71-d076-94358ca6413c"
      },
      "source": [
        "base_resnet = tf.keras.applications.ResNet101V2(include_top = False, \n",
        "                        input_shape=(image_size, image_size, 3),\n",
        "                        weights=\"imagenet\")\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.2, patience=5, min_lr=0.0001, cooldown=1)\n",
        "\n",
        "for layer in base_resnet.layers[:-5]:\n",
        "  layer.trainable = False\n",
        "\n",
        "head = base_resnet.output\n",
        "\n",
        "head = GlobalMaxPooling2D()(head)\n",
        "head = Flatten()(head)\n",
        "\n",
        "# head = Dense(128, activation='relu', kernel_initializer='he_normal', kernel_regularizer=regularizers.l1_l2(l1=0.01, l2=0.01))(head)\n",
        "# head = BatchNormalization()(head)\n",
        "\n",
        "head = Dense(64, activation='relu', kernel_initializer='he_normal', kernel_regularizer=regularizers.l1_l2(l2=0.01))(head)\n",
        "head = BatchNormalization()(head)\n",
        "\n",
        "head = Dense(5, activation ='softmax')(head)\n",
        "\n",
        "model = Model(inputs = base_resnet.input, outputs =head)\n",
        "\n",
        "model.compile(\n",
        "  optimizer = opt,\n",
        "  loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "  metrics=['accuracy']\n",
        ")\n",
        "\n",
        "\n",
        "opt = keras.optimizers.Adam(0.001) \n",
        "\n",
        "history1 = model.fit(df_train, validation_data= df_valid, steps_per_epoch=steps_per_epoch, validation_steps = valid_steps,\n",
        "                shuffle= True, epochs=100, callbacks=[early_stopping1, reduce_lr])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-6c21edd5f6e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m history1 = model.fit(df_train, validation_data= df_valid, steps_per_epoch=steps_per_epoch, validation_steps = valid_steps,\n\u001b[0;32m---> 34\u001b[0;31m                 shuffle= True, epochs=100, callbacks=[early_stopping1, reduce_lr])\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'early_stopping1' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x91R26j842zL"
      },
      "source": [
        "#### Learning rate decay with another model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztqrp2XtN0OR"
      },
      "source": [
        "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=1e-2,\n",
        "    decay_steps=10000,\n",
        "    decay_rate=0.9)\n",
        "optimizer = keras.optimizers.SGD(learning_rate=lr_schedule)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5n8f_4z3OIbi"
      },
      "source": [
        "opt = optimizer\n",
        "model = make_model1(opt, 0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dHwORgkZ1XY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "outputId": "21b60303-e85c-4436-95c3-1a1214aefb43"
      },
      "source": [
        "model.fit(df_train, validation_data= df_valid, steps_per_epoch=steps_per_epoch, validation_steps =valid_steps, \n",
        "                 shuffle= True, epochs=50, callbacks=[early_stopping1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "50/50 [==============================] - 52s 626ms/step - loss: 94.8769 - accuracy: 0.4154 - val_loss: 90.0078 - val_accuracy: 0.4679\n",
            "Epoch 2/50\n",
            "22/50 [============>.................] - ETA: 11s - loss: 89.0968 - accuracy: 0.6190"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-265-b3887b2e5124>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model.fit(df_train, validation_data= df_valid, steps_per_epoch=50, \n\u001b[0;32m----> 2\u001b[0;31m                  shuffle= True, epochs=50, callbacks=[early_stopping1])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nWMT1XPI371"
      },
      "source": [
        "### Xception"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbPa0wKhI2SM"
      },
      "source": [
        "Batzh_Size = 64\n",
        "steps_per_epoch = num_training// Batch_Size\n",
        "valid_steps = num_valid // Batch_Size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QP8tBJben4fl"
      },
      "source": [
        "checkpoint_cb = ModelCheckpoint(\"Cassava_best_model.h5\",\n",
        "                  save_best_only=True,\n",
        "                  monitor = 'val_loss',\n",
        "                  mode='min')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2vAvQGoqGCT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b27da7e4-f72c-40f6-9345-c21052d7ba1f"
      },
      "source": [
        "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.2,\n",
        "                    patience = 10, min_lr = 1e-6,\n",
        "                    mode = 'min', verbose = 1)\n",
        "\n",
        "base_resnet = tf.keras.applications.Xception(\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    input_shape= (image_size, image_size, 3))\n",
        "\n",
        "for layer in base_resnet.layers[40:]:\n",
        "  layer.trainable = True\n",
        "  \n",
        "for layer in base_resnet.layers:\n",
        "  if layer.name.endswith('_bn'):\n",
        "    layer.trainable = False\n",
        "head = base_resnet.output\n",
        "\n",
        "head = GlobalMaxPooling2D()(head)\n",
        "head = Flatten()(head)\n",
        "\n",
        "head = Dense(64, activation = 'relu', bias_regularizer=tf.keras.regularizers.L1L2(l1=0.01, l2=0.001))(head)\n",
        "head = BatchNormalization()(head)\n",
        "head = Dropout(0.5)(head)\n",
        "\n",
        "head = Dense(5, activation ='softmax')(head)\n",
        "\n",
        "model = Model(inputs = base_resnet.input, outputs =head)\n",
        "opt = keras.optimizers.Adam(0.001) \n",
        "\n",
        "model.compile(\n",
        "  optimizer = opt,\n",
        "  loss=keras.losses.SparseCategoricalCrossentropy(from_logits = False),\n",
        "  metrics=['accuracy']\n",
        ")\n",
        "\n",
        "h = model.fit(df_train, validation_data= df_valid, steps_per_epoch=steps_per_epoch, validation_steps=valid_steps,\n",
        "                    #validation_steps=valid_steps,\n",
        "                shuffle= True, epochs=300, callbacks=[checkpoint_cb])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83689472/83683744 [==============================] - 1s 0us/step\n",
            "Epoch 1/300\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-319b9acd9019>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m history = model.fit(df_train, validation_data= df_valid, steps_per_epoch=steps_per_epoch, validation_steps=valid_steps,\n\u001b[1;32m     36\u001b[0m                     \u001b[0;31m#validation_steps=valid_steps,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                 shuffle= True, epochs=300, callbacks=[checkpoint_cb])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[128,728,14,14] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node model/block10_sepconv3_bn/FusedBatchNormV3 (defined at <ipython-input-28-319b9acd9019>:37) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_8689]\n\nFunction call stack:\ntrain_function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IP4CZaSsYaQW"
      },
      "source": [
        "### Resnet101V2 with 3 dense layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLmKPSMWQb3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e92a4f54-a46d-47fb-9c11-387b727302f4"
      },
      "source": [
        "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.2,\n",
        "                    patience = 2, min_lr = 1e-6,\n",
        "                    mode = 'min', verbose = 1)\n",
        "base_resnet = tf.keras.applications.Xception(\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    input_shape=(224, 224, 3),\n",
        ")\n",
        "\n",
        "for layer in base_resnet.layers[:-5]:\n",
        "  layer.trainable = False\n",
        "#  print(layer, layer.trainable)\n",
        "\n",
        "for layer in base_resnet.layers:\n",
        "  if layer.name.endswith('_bn'):\n",
        "    layer.trainable = False\n",
        "\n",
        "head = base_resnet.output\n",
        "\n",
        "head = GlobalAveragePooling2D()(head)\n",
        "\n",
        "head = Flatten()(head)\n",
        "\n",
        "head = Dense(128, kernel_initializer='he_normal', bias_regularizer=tf.keras.regularizers.L1L2(l1=0.01, l2=0.001))(head)\n",
        "head = Activation('relu')(head)\n",
        "head = BatchNormalization()(head)\n",
        "head = Dropout(0.5)(head)\n",
        "\n",
        "head = Dense(64, kernel_initializer='he_normal', bias_regularizer=tf.keras.regularizers.L1L2(l1=0.01, l2=0.001))(head)\n",
        "head = Activation('relu')(head)\n",
        "head = BatchNormalization()(head)\n",
        "head = Dropout(0.3)(head)\n",
        "\n",
        "head = Dense(5, activation ='softmax')(head)\n",
        "\n",
        "model = Model(inputs = base_resnet.input, outputs =head)\n",
        "\n",
        "opt = keras.optimizers.Adam(0.01, beta_1=0.9,  beta_2=0.999) \n",
        "\n",
        "model.compile(\n",
        "  optimizer = opt,\n",
        "  loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "  metrics=['accuracy']\n",
        ")\n",
        "\n",
        "history = model.fit(df_train, validation_data= df_valid, steps_per_epoch=steps_per_epoch, \n",
        "                shuffle= True, epochs=100, callbacks=[reduce_lr])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1002/1002 [==============================] - 428s 419ms/step - loss: 6.0164 - accuracy: 0.6270 - val_loss: 2.7592 - val_accuracy: 0.6454\n",
            "Epoch 2/100\n",
            "1002/1002 [==============================] - 408s 407ms/step - loss: 2.9979 - accuracy: 0.6667 - val_loss: 4.0840 - val_accuracy: 0.4144\n",
            "Epoch 3/100\n",
            "1002/1002 [==============================] - 408s 407ms/step - loss: 2.9172 - accuracy: 0.6739 - val_loss: 3.3950 - val_accuracy: 0.4475\n",
            "\n",
            "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
            "Epoch 4/100\n",
            "1002/1002 [==============================] - 407s 407ms/step - loss: 1.3375 - accuracy: 0.6875 - val_loss: 2.2724 - val_accuracy: 0.3602\n",
            "Epoch 5/100\n",
            "1002/1002 [==============================] - 404s 404ms/step - loss: 1.2006 - accuracy: 0.6905 - val_loss: 1.3191 - val_accuracy: 0.6512\n",
            "Epoch 6/100\n",
            "1002/1002 [==============================] - 400s 399ms/step - loss: 1.2084 - accuracy: 0.6917 - val_loss: 1.2566 - val_accuracy: 0.6691\n",
            "Epoch 7/100\n",
            "1002/1002 [==============================] - 398s 397ms/step - loss: 1.2022 - accuracy: 0.6935 - val_loss: 2.0964 - val_accuracy: 0.4512\n",
            "Epoch 8/100\n",
            "1002/1002 [==============================] - 396s 395ms/step - loss: 1.2045 - accuracy: 0.6938 - val_loss: 1.2457 - val_accuracy: 0.6891\n",
            "Epoch 9/100\n",
            "1002/1002 [==============================] - 396s 396ms/step - loss: 1.2055 - accuracy: 0.6951 - val_loss: 1.2307 - val_accuracy: 0.6859\n",
            "Epoch 10/100\n",
            "1002/1002 [==============================] - 395s 394ms/step - loss: 1.2030 - accuracy: 0.6948 - val_loss: 1.2023 - val_accuracy: 0.6926\n",
            "Epoch 11/100\n",
            "1002/1002 [==============================] - 394s 393ms/step - loss: 1.2010 - accuracy: 0.6963 - val_loss: 1.3026 - val_accuracy: 0.6639\n",
            "Epoch 12/100\n",
            "1002/1002 [==============================] - 395s 394ms/step - loss: 1.2033 - accuracy: 0.6977 - val_loss: 1.5794 - val_accuracy: 0.5775\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
            "Epoch 13/100\n",
            "1002/1002 [==============================] - 398s 397ms/step - loss: 0.9390 - accuracy: 0.6997 - val_loss: 1.1313 - val_accuracy: 0.6239\n",
            "Epoch 14/100\n",
            "1002/1002 [==============================] - 396s 395ms/step - loss: 0.9019 - accuracy: 0.7057 - val_loss: 0.9849 - val_accuracy: 0.6822\n",
            "Epoch 15/100\n",
            "1002/1002 [==============================] - 395s 394ms/step - loss: 0.9005 - accuracy: 0.7061 - val_loss: 1.2503 - val_accuracy: 0.5788\n",
            "Epoch 16/100\n",
            "1002/1002 [==============================] - 398s 397ms/step - loss: 0.9058 - accuracy: 0.7042 - val_loss: 0.9852 - val_accuracy: 0.6797\n",
            "\n",
            "Epoch 00016: ReduceLROnPlateau reducing learning rate to 7.999999215826393e-05.\n",
            "Epoch 17/100\n",
            "1002/1002 [==============================] - 398s 397ms/step - loss: 0.8435 - accuracy: 0.7073 - val_loss: 0.9903 - val_accuracy: 0.6525\n",
            "Epoch 18/100\n",
            "1002/1002 [==============================] - 396s 395ms/step - loss: 0.8382 - accuracy: 0.7090 - val_loss: 1.0433 - val_accuracy: 0.6295\n",
            "\n",
            "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.599999814061448e-05.\n",
            "Epoch 19/100\n",
            "1002/1002 [==============================] - 396s 395ms/step - loss: 0.8224 - accuracy: 0.7087 - val_loss: 0.9824 - val_accuracy: 0.6459\n",
            "Epoch 20/100\n",
            "1002/1002 [==============================] - 399s 399ms/step - loss: 0.8163 - accuracy: 0.7101 - val_loss: 1.0254 - val_accuracy: 0.6254\n",
            "Epoch 21/100\n",
            "1002/1002 [==============================] - 400s 399ms/step - loss: 0.8114 - accuracy: 0.7103 - val_loss: 1.0073 - val_accuracy: 0.6336\n",
            "\n",
            "Epoch 00021: ReduceLROnPlateau reducing learning rate to 3.199999628122896e-06.\n",
            "Epoch 22/100\n",
            "1002/1002 [==============================] - 399s 399ms/step - loss: 0.8092 - accuracy: 0.7099 - val_loss: 0.9875 - val_accuracy: 0.6385\n",
            "Epoch 23/100\n",
            "1002/1002 [==============================] - 399s 398ms/step - loss: 0.8046 - accuracy: 0.7107 - val_loss: 0.9862 - val_accuracy: 0.6394\n",
            "\n",
            "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "Epoch 24/100\n",
            " 325/1002 [========>.....................] - ETA: 4:04 - loss: 0.8089 - accuracy: 0.7097"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-89-80f00af59fda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m history = model.fit(df_train, validation_data= df_valid, steps_per_epoch=steps_per_epoch, \n\u001b[0;32m---> 44\u001b[0;31m                 shuffle= True, epochs=100, callbacks=[reduce_lr])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHsZj98IvjAT"
      },
      "source": [
        "### Resnet101V2 with maxpooling after pre-trained"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkCUlvIoQb8C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "outputId": "99df126b-9070-4042-e264-ed12376beee3"
      },
      "source": [
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=0.00001)\n",
        "\n",
        "base_resnet = tf.keras.applications.ResNet101V2(include_top = False, \n",
        "                        input_shape=(image_size, image_size, 3),\n",
        "                        weights=\"imagenet\")\n",
        "\n",
        "for layer in base_resnet.layers[:-5]:\n",
        "  layer.trainable = False\n",
        "#  print(layer, layer.trainable)\n",
        "\n",
        "for layer in base_resnet.layers:\n",
        "  if layer.name.endswith('_bn'):\n",
        "    layer.trainable = False\n",
        "\n",
        "head = base_resnet.output\n",
        "\n",
        "head = GlobalMaxPooling2D()(head)\n",
        "head = Flatten()(head)\n",
        "\n",
        "head = Dense(64, kernel_initializer='he_normal', kernel_regularizer=regularizers.l1_l2(l2=0.001))(head)\n",
        "head = Activation('relu')(head)\n",
        "head = BatchNormalization()(head)\n",
        "head = Dropout(0.5)(head)\n",
        "\n",
        "head = Dense(5, activation ='softmax')(head)\n",
        "\n",
        "model = Model(inputs = base_resnet.input, outputs =head)\n",
        "\n",
        "opt = keras.optimizers.Adam(0.0001, beta_1=0.9,  beta_2=0.999) \n",
        "\n",
        "model.compile(\n",
        "  optimizer = opt,\n",
        "  loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "  metrics=['accuracy']\n",
        ")\n",
        "\n",
        "history = model.fit(df_train, validation_data= df_valid, steps_per_epoch=steps_per_epoch, \n",
        "                shuffle= True, epochs=100, callbacks=[reduce_lr, model_checkpoint_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-171b31dec55d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreduce_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.00001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m base_resnet = tf.keras.applications.ResNet101V2(include_top = False, \n\u001b[1;32m      4\u001b[0m                         \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                         weights=\"imagenet\")\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ReduceLROnPlateau' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuFNQkKCo5gh",
        "outputId": "62b0a51d-b68d-4a9a-bbab-bee1a8e9fff1"
      },
      "source": [
        "%tensorboard --logdir logs/data2040_midterm_project"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-16 20:40:21.699072: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\n",
            "***** TensorBoard Uploader *****\n",
            "\n",
            "This will upload your TensorBoard logs to https://tensorboard.dev/ from\n",
            "the following directory:\n",
            "\n",
            "logs\n",
            "\n",
            "This TensorBoard will be visible to everyone. Do not upload sensitive\n",
            "data.\n",
            "\n",
            "Your use of this service is subject to Google's Terms of Service\n",
            "<https://policies.google.com/terms> and Privacy Policy\n",
            "<https://policies.google.com/privacy>, and TensorBoard.dev's Terms of Service\n",
            "<https://tensorboard.dev/policy/terms/>.\n",
            "\n",
            "This notice will not be shown again while you are logged into the uploader.\n",
            "To log out, run `tensorboard dev auth revoke`.\n",
            "\n",
            "Continue? (yes/NO) yes\n",
            "\n",
            "Please visit this URL to authorize this application: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=373649185512-8v619h5kft38l4456nm2dj4ubeqsrvh6.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email&state=Q79YWDLOlRw787hSEALUPUA1PPdEGS&prompt=consent&access_type=offline\n",
            "Enter the authorization code: 4/1AY0e-g5RqDEB29gqA4NJEw1e1oL3vgBXeYSKdbN5_yE7RxS8uW3yiTA7c2o\n",
            "\n",
            "Data for the \"text\" plugin is now uploaded to TensorBoard.dev! Note that uploaded data is public. If you do not want to upload data for this plugin, use the \"--plugins\" command line argument.\n",
            "\n",
            "New experiment created. View your TensorBoard at: https://tensorboard.dev/experiment/yYQW0V6NQMS1f6VjRqmDrw/\n",
            "\n",
            "\u001b[1m[2021-03-16T20:45:09]\u001b[0m Started scanning logdir.\n",
            "\u001b[1m[2021-03-16T20:45:35]\u001b[0m Total uploaded: 64 scalars, 8823 tensors (11.6 MB), 1 binary objects (803.1 kB)\n",
            "\u001b[1m[2021-03-16T20:45:35]\u001b[0m Done scanning logdir.\n",
            "\n",
            "\n",
            "Done. View your TensorBoard at https://tensorboard.dev/experiment/yYQW0V6NQMS1f6VjRqmDrw/\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}